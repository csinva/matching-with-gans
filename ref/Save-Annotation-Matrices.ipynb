{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "\n",
    "BASE_DIR = '../datasets/octets-1/'\n",
    "ANNOTATIONS_DIR = BASE_DIR + 'annotations'\n",
    "LABELS_FILE = '/annotation-tool/data.json'\n",
    "OUT_MANIFEST_FILE = '/manifests/output/output.manifest'\n",
    "WORKERS_RESPONSE = '/annotations/worker-response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class annotationDatabase():\n",
    "    \n",
    "    def __init__(self,annotations_file_names, labelScores):\n",
    "        '''Parameters:\n",
    "        annotations_file_names - list of names of jupyter files where the annotations are saved.\n",
    "        Each file refers to one image.'''\n",
    "        self.annotators = {}           # dictionary that maps the unique ID strings of annotators to local integer IDs\n",
    "        self.annotator_names = []      # list of the unique string identifiers that AMT uses sorted by integer ID\n",
    "        self.annotations = []          # list of the number of annotations per annotator\n",
    "        self.N_ANNOTATORS = len(self.annotators)\n",
    "        self.N_IMAGES = len(annotations_file_names)\n",
    "        self.imageScores = []          # scores this image received -- list of lists\n",
    "        self.imageAnnotators = []      # annotators who worked on a given image -- list of lists\n",
    "        \n",
    "        #\n",
    "        # for each file extract all the useful annotations\n",
    "        #\n",
    "        for i, fname in enumerate(annotations_file_names):\n",
    "            with open(fname, 'r') as read_file:\n",
    "                data = json.load(read_file)                  # open the json file and read its contents into data\n",
    "                scores = []                                  # initialize the two lists of scores and IDs for the current image\n",
    "                annotatorIDs = []\n",
    "                for a,ans in enumerate(data['answers']):     # read each annotator's annotation\n",
    "                    ID = self.addAnnotation(ans['workerId']) # mark annotation and retrieve ID of annotator\n",
    "                    annotatorIDs.append(ID)                  # take note of which annotator it was\n",
    "                    label = data['answers'][a]['answerContent']['crowd-image-classifier']['label']\n",
    "                    scores.append(labelScores[label]) # transform label into score\n",
    "                    \n",
    "                self.imageScores.append(scores)\n",
    "                self.imageAnnotators.append(annotatorIDs)\n",
    "        \n",
    "        print(f'Found {self.N_IMAGES} images and {self.N_ANNOTATORS} annotators.')\n",
    "        \n",
    "    def addAnnotation(self,annotator_name):\n",
    "        '''Keep track of the annotations and of the annotators'''\n",
    "        try:\n",
    "            ID = self.annotators[annotator_name] # the annotator was found, here is her ID\n",
    "            self.annotations[ID] += 1 # chalk up one more annotation for this annotator\n",
    "        except: # the annotator was not on the list\n",
    "            ID = self.N_ANNOTATORS # create a new ID\n",
    "            self.annotators[annotator_name] = ID\n",
    "            self.N_ANNOTATORS +=1\n",
    "            self.annotations.append(1) # add a count of one for the last annotator\n",
    "            self.annotator_names.append(annotator_name)\n",
    "        return ID\n",
    "    \n",
    "    def annotatorID(self,annotator_name):\n",
    "        '''Retrieve the integer ID of an annotator from his/her name string'''\n",
    "        try:\n",
    "            ID = self.annotators[annotator_name] # the annotator was found, here is her ID\n",
    "        except: # the annotator was not on the list\n",
    "            ID = -1\n",
    "            print(f'Annotator {annotator_name} not found in annotator directory. Something is wrong.')\n",
    "        return ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images and 590 annotators.\n",
      "perona-causal-faces-age-015\n",
      "Found 8000 images and 559 annotators.\n",
      "perona-causal-faces-ethnicity-015\n",
      "Found 8000 images and 480 annotators.\n",
      "perona-causal-faces-facial-hair-15\n",
      "Found 8000 images and 559 annotators.\n",
      "perona-causal-faces-gender-015\n",
      "Found 8000 images and 514 annotators.\n",
      "perona-causal-faces-hair-length-015\n",
      "Found 8000 images and 484 annotators.\n",
      "perona-causal-faces-makeup-015\n",
      "Found 8000 images and 489 annotators.\n",
      "perona-causal-faces-skin-color-015\n",
      "Found 8000 images and 534 annotators.\n",
      "perona-causal-faces-smile-015\n",
      "Found 8000 images and 587 annotators.\n",
      "perona-causal-faces-uncanny-015\n",
      "[['Child', 'Teen', 'Young adult', 'Adult', 'Middle age', 'Senior'], ['East Asian', 'South Asian', 'African', 'Latino', 'Middle East', 'Caucasian'], ['None', 'Minimal', 'Regular', 'Heavy'], ['Female', 'Probably female', 'In between', 'Probably male', 'Male'], ['Very short', 'Short', 'Medium', 'Long', 'Very long'], ['None', 'Minimal', 'Full', 'Showy'], ['Light', 'Fair', 'Medium', 'Olive', 'Brown', 'Black'], ['Broad smile', 'Smile', 'Neutral', 'Serious', 'Frown'], ['Real for sure', 'Likely real', 'Uncertain', 'Likely fake', 'Fake for sure']]\n"
     ]
    }
   ],
   "source": [
    "# Get list of experiments in annotation dir. Alternatively, specify ones you care about.\n",
    "experiments = [os.path.split(f)[1] for f in glob.glob(os.path.join(ANNOTATIONS_DIR, '*'))]\n",
    "\n",
    "scores = []\n",
    "labels = []\n",
    "\n",
    "for EXPERIMENT_LABEL in experiments:\n",
    "    ANNOTATIONS_PATH = f'{ANNOTATIONS_DIR}/{EXPERIMENT_LABEL}{WORKERS_RESPONSE}'\n",
    "    OUT_MANIFEST_PATH = f'{ANNOTATIONS_DIR}/{EXPERIMENT_LABEL}{OUT_MANIFEST_FILE}'\n",
    "    LABELS_PATH = f'{ANNOTATIONS_DIR}/{EXPERIMENT_LABEL}{LABELS_FILE}'\n",
    "\n",
    "    #Read labels using annotation-tool/data.json and assign integers to labels \n",
    "    with open(LABELS_PATH, 'r') as labels_file:\n",
    "        labels_data = json.load(labels_file)['labels']\n",
    "        LABELS = [l['label'] for l in labels_data]\n",
    "    labelScores = {l:i for (i, l) in enumerate(LABELS)} # generate numerical scores for the labels - useful in regression\n",
    "    labels.append(LABELS)\n",
    "    \n",
    "    # Make map from annotation index to image index\n",
    "    idx_map = []\n",
    "    with jsonlines.open(OUT_MANIFEST_PATH) as reader:\n",
    "        for obj in reader:\n",
    "            _, name = os.path.split(obj['source-ref']) #remove leading path\n",
    "            idx = name.split('.')[0]\n",
    "            idx_map.append(idx)\n",
    "  \n",
    "\n",
    "    # Make annotation file name list in proper order\n",
    "    annotation_file_names = []\n",
    "    for i in range(len(idx_map)):\n",
    "        idx = idx_map.index(i)\n",
    "        annotation_file_names += glob.glob(ANNOTATIONS_PATH + '/*/%d/*.json'% idx)\n",
    "        \n",
    "    # Make annotation file name list in proper order (keep same order)\n",
    "    #annotation_file_names = []\n",
    "    #for i in range(len(idx_map)):\n",
    "    #    annotation_file_names += glob.glob(ANNOTATIONS_PATH + '/*/%d/*.json'% i)\n",
    "    \n",
    "    # put together the database of the annotator IDs and their work\n",
    "    annotations = annotationDatabase(annotation_file_names, labelScores)\n",
    "    x = np.array(annotations.imageScores) #[:, 0:7]\n",
    "    scores.append(x)\n",
    "    print(EXPERIMENT_LABEL)\n",
    "\n",
    "scores = np.stack(scores, 2) \n",
    "output = open(BASE_DIR + '/data/scores-humans.pkl', 'wb')\n",
    "pickle.dump([scores, labels], output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}