{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join as oj\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import sklearn.model_selection\n",
    "import models\n",
    "import util\n",
    "import os\n",
    "import config\n",
    "import viz\n",
    "import scipy.stats\n",
    "from tqdm import tqdm\n",
    "import figs\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import face_recognition\n",
    "import dlib\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crop and detect faces in real ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(image):\n",
    "\n",
    "    # Create a face detector\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    # Run detector and get bounding boxes of the faces on image.\n",
    "    detected_faces = face_detector(image, 1)\n",
    "    face_frames = [(x.left(), x.top(),\n",
    "                    x.right(), x.bottom()) for x in detected_faces]\n",
    "\n",
    "    return face_frames\n",
    "\n",
    "# Load image\n",
    "def crop_and_resize_ims(dir_base='../data/pilot-our-images/',\n",
    "                        dir_out_base='../data_processed/pilot-our-images-large',\n",
    "                        MULT = 1.6):\n",
    "    for folder in os.listdir(dir_base):\n",
    "        dir_in = oj(dir_base, folder)\n",
    "        dir_out = oj(dir_out_base, folder)\n",
    "        os.makedirs(dir_out, exist_ok=True)\n",
    "\n",
    "        im_num = 0\n",
    "        for fname in sorted(os.listdir(dir_in)):\n",
    "            if '.jpg' in fname:\n",
    "                img_path = oj(dir_in, fname)\n",
    "                image = io.imread(img_path)\n",
    "\n",
    "                # Detect faces\n",
    "                detected_faces = detect_faces(image)\n",
    "                if len(detected_faces) > 0:\n",
    "\n",
    "                    # Crop faces and plot\n",
    "                    (left, upper, right, lower) = detected_faces[0]\n",
    "                    \n",
    "                    mid = (left + right) // 2\n",
    "                    diff = (mid - left) * MULT\n",
    "                    left = mid - diff\n",
    "                    right = mid + diff\n",
    "                    \n",
    "                    mid = (lower + upper) // 2\n",
    "                    diff = (mid - lower) * MULT\n",
    "                    upper = mid + diff\n",
    "                    lower = mid - diff                   \n",
    "\n",
    "                    im_face = Image.fromarray(image).crop((left, upper, right, lower))\n",
    "                    dim_min = min(im_face.width, im_face.height)\n",
    "                    im_face = im_face.crop((0, 0, dim_min, dim_min)) # im_face[:dim_min, :dim_min]\n",
    "                    im_face = im_face.resize((1024, 1024))\n",
    "                    \n",
    "                    '''\n",
    "                    util.imshow(np.asarray(im_face))\n",
    "                    plt.show()\n",
    "                    '''\n",
    "\n",
    "                    \n",
    "                    # save\n",
    "                    out_fname = oj(dir_out, f'{folder}_{im_num:03d}.jpg')\n",
    "                    im_face.save(out_fname)\n",
    "                    im_num += 1\n",
    "\n",
    "crop_and_resize_ims()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lower res ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('stylegan2encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMS = 100\n",
    "out_dir = ''\n",
    "for fname in sorted(os.listdir(config.DIR_CELEBA_IMS))[N_IMS]:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import projector\n",
    "import pretrained_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"gdrive:networks/stylegan2-ffhq-config-f.pkl\"...\n"
     ]
    }
   ],
   "source": [
    "network_pkl='gdrive:networks/stylegan2-ffhq-config-f.pkl'\n",
    "vgg16_pkl='https://drive.google.com/uc?id=1N2-m9qszOeVC9Tq77WxsLnuWwOedQiD2'\n",
    "num_steps=1000\n",
    "initial_learning_rate=0.1\n",
    "initial_noise_factor=0.05\n",
    "verbose=False\n",
    "regularize_mean_deviation_weight=0.1\n",
    "_G, _D, Gs = pretrained_networks.load_networks(network_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading networks from \"%s\"...' % network_pkl)\n",
    "\n",
    "proj = projector.Projector(\n",
    "    vgg16_pkl             = vgg16_pkl,\n",
    "    num_steps             = num_steps,\n",
    "    initial_learning_rate = initial_learning_rate,\n",
    "    initial_noise_factor  = initial_noise_factor,\n",
    "    verbose               = verbose,\n",
    "    regularize_mean_deviation_weight = regularize_mean_deviation_weight\n",
    ")\n",
    "proj.set_network(Gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parser = argparse.ArgumentParser(description='Project real-world images into StyleGAN2 latent space')\n",
    "# parser.add_argument('src_dir', help='Directory with aligned images for projection')\n",
    "# parser.add_argument('dst_dir', help='Output directory')\n",
    "# parser.add_argument('--tmp-dir', default='.stylegan2-tmp', help='Temporary directory for tfrecords and video frames')\n",
    "# parser.add_argument('--network-pkl', default='gdrive:networks/stylegan2-ffhq-config-f.pkl', help='StyleGAN2 network pickle filename')\n",
    "# parser.add_argument('--vgg16-pkl', default='https://drive.google.com/uc?id=1N2-m9qszOeVC9Tq77WxsLnuWwOedQiD2', help='VGG16 network pickle filename')\n",
    "# parser.add_argument('--num-steps', type=int, default=1000, help='Number of optimization steps')\n",
    "# parser.add_argument('--initial-learning-rate', type=float, default=0.1, help='Initial learning rate')\n",
    "# parser.add_argument('--initial-noise-factor', type=float, default=0.05, help='Initial noise factor')\n",
    "# parser.add_argument('--verbose', type=bool, default=False, help='Verbose output')\n",
    "# parser.add_argument('--video', type=bool, default=False, help='Render video of the optimization process')\n",
    "# parser.add_argument('--video-mode', type=int, default=1, help='Video mode: 1 for optimization only, 2 for source + optimization')\n",
    "# parser.add_argument('--video-size', type=int, default=1024, help='Video size (height in px)')\n",
    "# parser.add_argument('--video-fps', type=int, default=25, help='Video framerate')\n",
    "# parser.add_argument('--video-codec', default='libx264', help='Video codec')\n",
    "# parser.add_argument('--video-bitrate', default='5M', help='Video bitrate')\n",
    "\n",
    "\n",
    "\n",
    "# parser.add_argument('--regularize_mean_deviation_weight', type=float, default=0, help='Penalize different w vectors to be the same')\n",
    "\n",
    "\n",
    "src_files = sorted([os.path.join(args.src_dir, f) for f in os.listdir(args.src_dir) if f[0] not in '._'])\n",
    "for src_file in src_files:\n",
    "    # check if file already exists and skip\n",
    "    filename = os.path.join(args.dst_dir, os.path.basename(src_file)[:-4] + '.png')\n",
    "    if not os.path.exists(filename):\n",
    "\n",
    "        project_image(proj, src_file, args.dst_dir, args.tmp_dir, video=args.video)\n",
    "        if args.video:\n",
    "            render_video(\n",
    "                src_file, args.dst_dir, args.tmp_dir, args.num_steps, args.video_mode,\n",
    "                args.video_size, args.video_fps, args.video_codec, args.video_bitrate\n",
    "            )\n",
    "        shutil.rmtree(args.tmp_dir)\n",
    "    else:\n",
    "        print('skipping', filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
