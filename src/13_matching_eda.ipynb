{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join as oj\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import models\n",
    "import util\n",
    "import os\n",
    "import config\n",
    "from config import ATTR_TO_INDEX\n",
    "import viz\n",
    "import scipy.stats\n",
    "from tqdm import tqdm\n",
    "import figs\n",
    "import matplotlib.image as mpimg\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import seaborn as sns\n",
    "import data\n",
    "import transects\n",
    "import face_recognition\n",
    "import sklearn.metrics\n",
    "from matching import *\n",
    "from matplotlib.image import BboxImage\n",
    "from matplotlib.transforms import Bbox, TransformedBbox\n",
    "\n",
    "\n",
    "df = data.load_all_labs()\n",
    "df = df.set_index('fname_id')\n",
    "\n",
    "DIR_ORIG = '../data/celeba-hq/ims/'\n",
    "reg = 0.1\n",
    "DIR_GEN = oj(f'../data_processed/celeba-hq/generated_images_{reg}')\n",
    "\n",
    "# get fnames\n",
    "fname_nps = [f for f in sorted(os.listdir(DIR_GEN)) if 'npy' in f] # these start at 00001\n",
    "fname_ids = np.array([f[:-4] for f in fname_nps])\n",
    "idxs_calculated = np.array([int(x) - 1 for x in fname_ids]) # this starts at 0\n",
    "\n",
    "# trim df to only have the relevant ids\n",
    "df = df.loc[fname_ids]\n",
    "\n",
    "# load the linear model in latent space\n",
    "coefs, intercepts = transects.get_directions()\n",
    "coefs = np.array(coefs).squeeze()\n",
    "intercepts = np.array(intercepts)\n",
    "\n",
    "\n",
    "# load latents and calculate dists\n",
    "print('loading latents...')\n",
    "latents = np.array([np.load(oj(DIR_GEN, f)) for f in fname_nps])\n",
    "lats = get_lat(latents)\n",
    "preds = latents.mean(axis=1) @ coefs.T + intercepts.T\n",
    "weights = np.zeros(preds.shape[1])\n",
    "# print(ATTR_TO_INDEX)\n",
    "# weights[ATTR_TO_INDEX['skin-color']] = 1e2\n",
    "vecs = join_vecs(preds, lats, weights)\n",
    "\n",
    "print('calculating dists...')\n",
    "dists_gan = get_dists(vecs)\n",
    "print('done!')\n",
    "\n",
    "# load pairwise facial dicts\n",
    "print('loading facial rec dists...')\n",
    "dists_facial = np.load(open('processed/13_facial_dists_pairwise.npy', 'rb')) # pkl.load()\n",
    "dists_facial = dists_facial[idxs_calculated, :][:, idxs_calculated]\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find matching for an im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img 38 is a good gender example\n",
    "for im_idx in range(10):# range(38, 45):\n",
    "    \n",
    "    # select subset of indices to use for matching\n",
    "    idxs = np.ones(df.shape[0]).astype(bool)\n",
    "#     idxs = (df['gender'] > 0).values\n",
    "#     idxs = (df['race'] == 'Black').values\n",
    "#     idxs = (df['Eyeglasses'] > 0).values\n",
    "    dists_im = dists_gan[im_idx][idxs] # first select row, then select vals\n",
    "#     dists_im = dists_facial[im_idx][idxs]\n",
    "    fname_ids_for_matching = fname_ids[idxs]    \n",
    "    \n",
    "    closest_match_vals, closest_matches_fnames = calc_matches(dists_im, fname_ids_for_matching)\n",
    "    # print(closest_matches_fnames)\n",
    "    \n",
    "    # load images\n",
    "    N_MATCHES_TO_PLOT = 5\n",
    "    fname_id = fname_ids[im_idx]\n",
    "    im_orig = mpimg.imread(oj(DIR_ORIG, f'{fname_id}.jpg'))\n",
    "    im_rec = mpimg.imread(oj(DIR_GEN, f'{fname_id}.png'))\n",
    "    im_matches = [mpimg.imread(oj(DIR_GEN, f'{fname_match}.png'))\n",
    "                  for fname_match in closest_matches_fnames[:N_MATCHES_TO_PLOT]]\n",
    "    \n",
    "    # plt images\n",
    "    util.plot_row([im_orig, im_rec] + im_matches,\n",
    "                  annot_list=['orig', 'rec'] + closest_match_vals[:N_MATCHES_TO_PLOT].round(3).tolist(), dpi=150)\n",
    "    plt.show()\n",
    "    # print(closest_matches, closest_matches_fnames)\n",
    "# show_matches(dists_gan, DIR_ORIG, DIR_GEN, im_nums=range(5, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**simple dim reduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(xs, ys, im):\n",
    "    '''Note: should normalize x/y coords to 0-1 before plotting\n",
    "    '''\n",
    "    for idx, (x, y) in tqdm(enumerate(zip(xs, ys))):\n",
    "        bb = Bbox.from_bounds(x, y, IM_SIZE, IM_SIZE)  \n",
    "        bb2 = TransformedBbox(bb, ax.transData)\n",
    "        bbox_image = BboxImage(bb2, origin=None, clip_on=False)\n",
    "        bbox_image.set_data(im[idx])\n",
    "#          bbox_image.set_alpha(1.0)\n",
    "        ax.add_artist(bbox_image)\n",
    "    return ax\n",
    "\n",
    "# plot\n",
    "N_IMS = 1000\n",
    "IM_SIZE = 0.025\n",
    "N_PLOT = 1000\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20), dpi=100)\n",
    "ax = fig.add_subplot(111)\n",
    "ims = [mpimg.imread(oj(DIR_ORIG, f))[::2, ::2] for f in df.fname_final[:N_IMS]]\n",
    "l = sklearn.decomposition.PCA(n_components=2).fit_transform(lats[:N_IMS])\n",
    "# l = sklearn.manifold.TSNE().fit_transform(lats[:N_IMS])\n",
    "l = (l - l.min(axis=0)) / (l.max(axis=0) - l.min(axis=0))\n",
    "ax = plot_image(l[:N_PLOT, 0], l[:N_PLOT, 1], ims)\n",
    "plt.xlabel('Dim 1')\n",
    "plt.ylabel('Dim 2')\n",
    "# plt.xlim((0.5, 1))\n",
    "# plt.ylim((0, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots for specific ids/matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**make some plots for a specific match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_idx = 38 # img 38 is a good gender example\n",
    "fname_id2 = '02638' # this is the match\n",
    "# if all images are calculated, then this is just 5-char string of im_idx + 1\n",
    "fname_id = fname_ids[im_idx] \n",
    "\n",
    "\n",
    "# idxs\n",
    "dists_im = dists_gan[im_idx]\n",
    "\n",
    "im = mpimg.imread(oj(DIR_ORIG, f'{fname_id}.jpg'))\n",
    "im2 = mpimg.imread(oj(DIR_ORIG, f'{fname_id2}.jpg'))\n",
    "\n",
    "d1 = df[df.id == df.loc[fname_id].id]\n",
    "d2 = df[df.id == df.loc[fname_id2].id]\n",
    "\n",
    "\n",
    "\n",
    "util.plot_row([im, im2])\n",
    "util.plot_row([mpimg.imread(oj(DIR_ORIG, f)) for f in d1.fname_final])\n",
    "util.plot_row([mpimg.imread(oj(DIR_ORIG, f)) for f in d2.fname_final])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**look at images / reconstructions of the same person**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df[df['count_with_this_id'] >= df['count_with_this_id'].max() - 1]\n",
    "dd = d[d.id == d.iloc[0].id]\n",
    "util.plot_row([mpimg.imread(oj(DIR_ORIG, f)) for f in dd.fname_final][:5])\n",
    "util.plot_row([mpimg.imread(oj(DIR_GEN, f'{index}.png')) for index in dd.index][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate matching with metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**how often do we return the same id?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_match_names = ['facial', 'gan', 'gan_constrained']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:16<00:00, 13.14it/s]\n",
      "100%|██████████| 1000/1000 [01:13<00:00, 13.55it/s]\n",
      "100%|██████████| 1000/1000 [01:14<00:00, 13.45it/s]\n"
     ]
    }
   ],
   "source": [
    "d = df[df['count_with_this_id'] > 1]\n",
    "# print(d.shape)\n",
    "accs_keys = ['acc_top1', 'acc_top5', 'acc_top10']\n",
    "attr_keys = [kk for kk in df.keys() if not 'scores' in kk]\n",
    "r = {\n",
    "    k: [] for k in accs_keys + attr_keys\n",
    "}\n",
    "\n",
    "for dists_match_name in dists_match_names:\n",
    "    if dists_match_name == 'facial':\n",
    "        dists_match = dists_facial\n",
    "    elif dists_match_name == 'gan':\n",
    "        dists_match = dists_gan\n",
    "    elif dists_match_name == 'gan_constrained':\n",
    "        dists_match = dists_gan + (dists_facial > 0.6) * 1e3 # constraint for missclassificaiton\n",
    "    lists = {\n",
    "        k: [] for k in r.keys()\n",
    "    }\n",
    "    \n",
    "    for im_idx in tqdm(range(1000)):\n",
    "        id_orig = df.iloc[im_idx].id\n",
    "\n",
    "        # id retention\n",
    "        dists_im = dists_match[im_idx]\n",
    "        matched_idxs = np.argsort(dists_im)\n",
    "        matched_ids = df.iloc[matched_idxs].id.values # note - this needs to be df not d to get the proper indices from dists\n",
    "        lists['acc_top1'].append(id_orig in matched_ids[:1])\n",
    "        lists['acc_top5'].append(id_orig in matched_ids[:5])\n",
    "        lists['acc_top10'].append(id_orig in matched_ids[:10])\n",
    "        \n",
    "        \n",
    "        # are other feats matched?\n",
    "        d = df.iloc[matched_idxs[:10]]\n",
    "        for k in attr_keys:\n",
    "            orig = df.iloc[im_idx]\n",
    "            # print(d[k], orig[k], len(lists[k]))\n",
    "            lists[k].append(np.mean(d[k] == orig[k]))\n",
    "        \n",
    "    for k in lists.keys():\n",
    "        r[k].append(np.mean(lists[k]))\n",
    "#     r['acc_top1'].append(np.mean(acc_top1))\n",
    "#     r['acc_top5'].append(np.mean(acc_top5))\n",
    "#     r['acc_top10'].append(np.mean(acc_top10))\n",
    "r = pd.DataFrame.from_dict(r)\n",
    "r.to_pickle('processed/13_dist_stats.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skin-color 0.006\n",
      "Bangs 0.029\n",
      "Blurry 0.002\n",
      "Eyeglasses 0.006\n",
      "Pale_Skin 0.006\n",
      "Wavy_Hair 0.022\n",
      "Wearing_Hat 0.021\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_top1</th>\n",
       "      <th>acc_top5</th>\n",
       "      <th>acc_top10</th>\n",
       "      <th>idx</th>\n",
       "      <th>orig_idx</th>\n",
       "      <th>orig_file</th>\n",
       "      <th>proc_md5</th>\n",
       "      <th>final_md5</th>\n",
       "      <th>id</th>\n",
       "      <th>fname_final</th>\n",
       "      <th>...</th>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <th>Wearing_Necklace</th>\n",
       "      <th>Wearing_Necktie</th>\n",
       "      <th>Young</th>\n",
       "      <th>face_name_align_pred</th>\n",
       "      <th>race_pred</th>\n",
       "      <th>race4_pred</th>\n",
       "      <th>gender_pred</th>\n",
       "      <th>age_pred</th>\n",
       "      <th>img_names_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>facial</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan</th>\n",
       "      <td>0.178</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan_constrained</th>\n",
       "      <td>0.630</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 acc_top1  acc_top5  acc_top10  idx  orig_idx  orig_file  \\\n",
       "facial              0.906     0.935      0.937  0.0       0.0        0.0   \n",
       "gan                 0.178     0.250      0.291  0.0       0.0        0.0   \n",
       "gan_constrained     0.630     0.815      0.867  0.0       0.0        0.0   \n",
       "\n",
       "                 proc_md5  final_md5     id  fname_final  ...  \\\n",
       "facial                0.0        0.0  0.596          0.0  ...   \n",
       "gan                   0.0        0.0  0.046          0.0  ...   \n",
       "gan_constrained       0.0        0.0  0.410          0.0  ...   \n",
       "\n",
       "                 Wearing_Lipstick  Wearing_Necklace  Wearing_Necktie  Young  \\\n",
       "facial                      0.841             0.705            0.930  0.871   \n",
       "gan                         0.769             0.700            0.868  0.749   \n",
       "gan_constrained             0.848             0.702            0.924  0.860   \n",
       "\n",
       "                 face_name_align_pred  race_pred  race4_pred  gender_pred  \\\n",
       "facial                            0.0      0.881       0.935        0.942   \n",
       "gan                               0.0      0.632       0.776        0.842   \n",
       "gan_constrained                   0.0      0.840       0.920        0.948   \n",
       "\n",
       "                 age_pred  img_names_pred  \n",
       "facial              0.725             0.0  \n",
       "gan                 0.693             0.0  \n",
       "gan_constrained     0.732             0.0  \n",
       "\n",
       "[3 rows x 63 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "r = pd.read_pickle('processed/13_dist_stats.pkl').round(3)\n",
    "r.index = dists_match_names\n",
    "for k in r.keys():\n",
    "    if r.loc['gan', k] > r.loc['facial', k]:\n",
    "        print(k, f\"{r.loc['gan', k] - r.loc['facial', k]:0.3f}\")\n",
    "r #.round(3).style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {\n",
    "    'acc_top1': 'ID (top1)',\n",
    "    'gender': 'Gender',\n",
    "    'race_pred': 'Race'\n",
    "}\n",
    "r.index = ['Facial-rec dist', 'GAN dist', 'Combined']\n",
    "r2 = r[['acc_top1', 'gender', 'race_pred', 'Mustache', 'Blurry', 'Eyeglasses', 'Bangs', 'Wearing_Hat']].rename(columns=rename) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "{} &  ID (top1) &  Gender &  Race &  Mustache &  Blurry &  Eyeglasses &  Bangs &  Wearing\\_Hat \\\\\n",
      "\\midrule\n",
      "Facial-rec dist &       90.6 &    98.9 &  88.1 &      95.6 &    98.5 &        96.0 &   79.1 &         95.6 \\\\\n",
      "GAN dist        &       17.8 &    84.3 &  63.2 &      94.8 &    98.7 &        96.6 &   82.0 &         97.7 \\\\\n",
      "Combined        &       63.0 &    98.8 &  84.0 &      95.6 &    98.6 &        96.6 &   79.4 &         97.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(r2.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idx', 'orig_idx', 'orig_file', 'proc_md5', 'final_md5', 'id',\n",
       "       'fname_final', 'count_with_this_id', 'gender', 'hair-length',\n",
       "       'facial-hair', 'makeup', 'skin-color', 'age', '5_o_Clock_Shadow',\n",
       "       'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', 'Bangs',\n",
       "       'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair', 'Blurry',\n",
       "       'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses',\n",
       "       'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Male',\n",
       "       'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard',\n",
       "       'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
       "       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair',\n",
       "       'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick',\n",
       "       'Wearing_Necklace', 'Wearing_Necktie', 'Young', 'face_name_align_pred',\n",
       "       'race_pred', 'race4_pred', 'gender_pred', 'age_pred',\n",
       "       'race_scores_fair_pred', 'race_scores_fair_4_pred',\n",
       "       'gender_scores_fair_pred', 'age_scores_fair_pred', 'img_names_pred',\n",
       "       'background_mean', 'background_std', 'quality', 'White_prob',\n",
       "       'Black_prob', 'Asian_prob', 'Indian_prob'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
