{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join as oj\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import models\n",
    "import util\n",
    "import os\n",
    "import config\n",
    "from config import ATTR_TO_INDEX\n",
    "import viz\n",
    "import scipy.stats\n",
    "from tqdm import tqdm\n",
    "import figs\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import data\n",
    "import transects\n",
    "import face_recognition\n",
    "import sklearn.metrics\n",
    "from matching import *\n",
    "CELEB_IMS_DIR = '../data/celeba-hq/ims/'\n",
    "CELEB_ANNO_DIR = '../data/celeba-hq/Anno/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading labels...\n",
      "done loading!\n",
      "loading latents...\n",
      "calclating dists...\n"
     ]
    }
   ],
   "source": [
    "# load and merge all the data\n",
    "print('loading labels...')\n",
    "df = data.load_ids()\n",
    "labs, labs_full = data.load_labs()\n",
    "for k in labs.keys():\n",
    "    df[k] = labs[k].values\n",
    "for k in labs_full.keys():\n",
    "    df[k] = labs_full[k].values\n",
    "df['fname_id'] = df['fname_final'].str.slice(stop=-4)\n",
    "print('done loading!')\n",
    "\n",
    "DIR_ORIG = '../data/celeba-hq/ims/'\n",
    "# IM_NUMS = np.arange(1, 1301)\n",
    "\n",
    "DIRS_GEN = '../data_processed/celeba-hq/'\n",
    "reg = 0.1\n",
    "DIR_GEN = oj(DIRS_GEN, f'generated_images_{reg}')\n",
    "\n",
    "# get fnames\n",
    "fname_nps = [f for f in sorted(os.listdir(DIR_GEN)) if 'npy' in f]\n",
    "fname_ids = np.array([f[:-4] for f in fname_nps])\n",
    "\n",
    "# trim df to only have the relevant ids\n",
    "df = df.set_index('fname_id')\n",
    "df = df.loc[fname_ids]\n",
    "\n",
    "\n",
    "# load the linear model in latent space\n",
    "coefs, intercepts = transects.get_directions()\n",
    "coefs = np.array(coefs).squeeze()\n",
    "intercepts = np.array(intercepts)\n",
    "\n",
    "\n",
    "# load latents and calculate dists\n",
    "print('loading latents...')\n",
    "latents = np.array([np.load(oj(DIR_GEN, f)) for f in fname_nps])\n",
    "lats = get_lat(latents)\n",
    "preds = lats @ coefs.T + intercepts.T\n",
    "weights = np.zeros(preds.shape[1])\n",
    "# print(ATTR_TO_INDEX)\n",
    "# weights[ATTR_TO_INDEX['skin-color']] = 1e2\n",
    "vecs = join_vecs(preds, lats, weights)\n",
    "\n",
    "print('calclating dists...')\n",
    "dists = get_dists(vecs)\n",
    "print('done!')\n",
    "\n",
    "# load pairwise facial dicts\n",
    "dists_facial_dict = pkl.load(open('processed/13_facial_dists_pairwise.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find matches for an im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im_idx in range(10):\n",
    "    # if all images are calculated, then this is just 5-char string of im_idx + 1\n",
    "    fname_id = fname_ids[im_idx] \n",
    "    # print(fname_id)\n",
    "    im_fname = mpimg.imread(oj(DIR_ORIG, f'{fname_id}.jpg'))\n",
    "    \n",
    "    # idxs\n",
    "    dists_im = dists[im_idx]\n",
    "    \n",
    "    # select subset of indices to use for matching\n",
    "    idxs = (df['gender'] > 0).values\n",
    "#     idxs = (df['Eyeglasses'] > 0).values\n",
    "    dists_im = dists_im[idxs]\n",
    "    fname_ids_for_matching = fname_ids[idxs]    \n",
    "    \n",
    "    closest_match_vals, closest_matches_fnames = calc_matches(dists_im, fname_ids_for_matching)\n",
    "    # print(closest_match_vals)\n",
    "    \n",
    "    # load images\n",
    "    N_MATCHES_TO_PLOT = 5\n",
    "    im_orig = mpimg.imread(oj(DIR_ORIG, f'{fname_id}.jpg'))\n",
    "    im_rec = mpimg.imread(oj(DIR_GEN, f'{fname_id}.png'))\n",
    "    im_matches = [mpimg.imread(oj(DIR_GEN, f'{fname_match}.png'))\n",
    "                  for fname_match in closest_matches_fnames[:N_MATCHES_TO_PLOT]]\n",
    "    \n",
    "    # plt images\n",
    "    util.plot_row([im_orig, im_rec] + im_matches, dpi=50)\n",
    "    plt.show()\n",
    "    # print(closest_matches, closest_matches_fnames)\n",
    "# show_matches(dists, DIR_ORIG, DIR_GEN, im_nums=range(5, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how often does closest match have same identity\n",
    "(when there are many identities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3667, 54)\n"
     ]
    }
   ],
   "source": [
    "d = df[df['count_with_this_id'] > 1]\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
