{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join as oj\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import sklearn.model_selection\n",
    "import models\n",
    "import util\n",
    "import os\n",
    "import config\n",
    "import viz\n",
    "import scipy.stats\n",
    "from tqdm import tqdm\n",
    "import figs\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at stylegan-generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_ORIG = '../data/annotation-dataset-stylegan2/images'\n",
    "DIRS_STYLEGAN = '../data_processed/stylegan2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = [0, 0.1, 1, 10000]\n",
    "IM_NUMS = [0, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "R, C = len(IM_NUMS), 1 + len(regs)\n",
    "for r, IM_NUM in enumerate(IM_NUMS):\n",
    "    ims = []\n",
    "    latents = []\n",
    "    im_orig = mpimg.imread(oj(DIR_ORIG, f'{IM_NUM}.jpg'))\n",
    "    for reg in regs:\n",
    "        folder = f'generated_images_{reg}'\n",
    "        im_fname = oj(DIRS_STYLEGAN, folder, f'{IM_NUM}.png')\n",
    "        ims.append(mpimg.imread(im_fname))\n",
    "        latents.append(np.load(oj(DIRS_STYLEGAN, folder, f'{IM_NUM}.npy')))\n",
    "        print(np.mean(np.abs(np.corrcoef(latents[-1]))))\n",
    "\n",
    "    \n",
    "    plt.subplot(R, C, C * r + 1)\n",
    "    util.imshow(im_orig)\n",
    "\n",
    "    for i in range(len(regs)):\n",
    "        plt.subplot(R, C, C * r + 2 + i)\n",
    "        util.imshow(ims[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at CELEB-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_ORIG_CELEBA = '../data/CelebA/Img/img_align_celeba'\n",
    "DIR_SQUARE_CELEBA = '../data/CelebA/Img/img_square_celeba'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**need to first preprocess celeba to be square before running the pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in tqdm(sorted(os.listdir(DIR_ORIG_CELEBA))):\n",
    "    if '.jpg' in fname:\n",
    "        im = mpimg.imread(oj(DIR_ORIG_CELEBA, fname))\n",
    "        if not im.shape[0] == im.shape[1]:\n",
    "            im = im[20:-20]\n",
    "        plt.imsave(oj(DIR_SQUARE_CELEBA, fname), im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at celeba-hq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_ORIG = '../data/celeba-hq/ims/'\n",
    "DIRS_GEN = '../data_processed/celeba-hq/'\n",
    "regs = [0, 0.1, 1, 10000]\n",
    "IM_NUMS = np.arange(6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, C = len(IM_NUMS), 1 + len(regs)\n",
    "plt.figure(dpi=120, figsize=(C*2.5, R*2.5))\n",
    "for r, IM_NUM in enumerate(IM_NUMS):\n",
    "    ims = []\n",
    "    latents = []\n",
    "    im_orig = mpimg.imread(oj(DIR_ORIG, f'{IM_NUM:05}.jpg'))\n",
    "    for reg in regs:\n",
    "        folder = f'generated_images_{reg}'\n",
    "        im_fname = oj(DIRS_GEN, folder, f'{IM_NUM:05}.png')\n",
    "        ims.append(mpimg.imread(im_fname))\n",
    "        latents.append(np.load(oj(DIRS_GEN, folder, f'{IM_NUM:05}.npy')))\n",
    "        # print(np.mean(np.abs(np.corrcoef(latents[-1]))))\n",
    "\n",
    "    \n",
    "    plt.subplot(R, C, C * r + 1)\n",
    "    util.imshow(im_orig)\n",
    "    if r == 0:\n",
    "        plt.title('orig', fontsize=9)\n",
    "\n",
    "    for i in range(len(regs)):\n",
    "        plt.subplot(R, C, C * r + 2 + i)\n",
    "        util.imshow(ims[i])\n",
    "        if r == 0:\n",
    "            plt.title(f'reg={regs[i]:.2e}', fontsize=9)\n",
    "    latents = np.array(latents)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quantitative eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../models/stylegan2encoder')\n",
    "import pretrained_networks\n",
    "import projector\n",
    "sys.path.append('transects')\n",
    "from transects import make_transects, ganwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n"
     ]
    }
   ],
   "source": [
    "network_pkl = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'\n",
    "_, _, Gs = pretrained_networks.load_networks(network_pkl)\n",
    "proj = projector.Projector()\n",
    "proj.set_network(Gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_ORIG = '../data/celeba-hq/ims/'\n",
    "DIRS_GEN = '../data_processed/celeba-hq/'\n",
    "regs = [0, 0.1, 1, 10000]\n",
    "IM_NUMS = np.arange(6, 10)\n",
    "\n",
    "attr_map = {\n",
    "    'A': 'age',\n",
    "    'B': 'facial-hair',\n",
    "    'C': 'skin-color',\n",
    "    'G': 'gender',\n",
    "    'H': 'hair-length',\n",
    "    'M': 'makeup',\n",
    "}\n",
    "ks = sorted(attr_map.keys())\n",
    "all_attrs = ''.join(ks)\n",
    "coefs, intercepts = make_transects.get_directions(all_attrs=all_attrs)\n",
    "coefs = np.array(coefs).squeeze()\n",
    "intercepts = np.array(intercepts).flatten()\n",
    "\n",
    "\n",
    "def load_labs(celeba_labs_fname='../data/celeba-hq/Anno/list_attr_celeba.txt'):\n",
    "    labs_full = pd.read_csv(celeba_labs_fname, delim_whitespace=True, skiprows=1)\n",
    "    labs = pd.DataFrame()\n",
    "    # print(labs.keys())\n",
    "    # print(labs_full.keys())\n",
    "\n",
    "    # large is more male\n",
    "    labs['gender'] = labs_full['Male']\n",
    "\n",
    "    # larger is longer\n",
    "    labs['hair-length'] = -1 * labs_full['Bald'] # Bangs, Receding_Hairline\n",
    "\n",
    "    # larger is more\n",
    "    labs['facial-hair'] = labs_full['Mustache'] # Goatee, Mustache, No_Beard, 5_o_Clock_Shadow\n",
    "\n",
    "    # higher is more\n",
    "    labs['makeup'] = labs_full['Heavy_Makeup'] # Wearing_Lipstick\n",
    "\n",
    "    # higher is darker\n",
    "    labs['skin-color'] = labs_full['Pale_Skin'] * -1\n",
    "\n",
    "    # older is more positive\n",
    "    labs['age'] = labs_full['Young'] * -1\n",
    "    return labs\n",
    "\n",
    "labs = load_labs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:12<00:37, 12.65s/it]"
     ]
    }
   ],
   "source": [
    "# want df where each row is an (image, reg_param) set\n",
    "# columns represent different measure statistics\n",
    "r = {\n",
    "    k: []\n",
    "    for k in ['perceptual_loss', 'mean_abs_corr', 'im_num', 'reg_param'] +\n",
    "    [f'pred_{a}' for a in all_attrs] +\n",
    "    [f'lab_{a}' for a in all_attrs]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "IM_NUMS = np.arange(1, 5)\n",
    "regs = [0, 0.1, 1, 10000]\n",
    "\n",
    "for im_num in tqdm(IM_NUMS):\n",
    "    for reg in regs:\n",
    "        # save params\n",
    "        r['im_num'].append(im_num)\n",
    "        r['reg_param'].append(reg)\n",
    "        \n",
    "        # load image and latents\n",
    "        im_orig = mpimg.imread(oj(DIR_ORIG, f'{IM_NUM:05}.jpg'))\n",
    "        im_orig = np.expand_dims(np.transpose(im_orig, (2, 0, 1)), 0) # (1, 3, 1024, 1024)\n",
    "        latents = np.load(oj(DIRS_GEN, folder, f'{IM_NUM:05}.npy'))\n",
    "        latents = np.expand_dims(latents, 0) # (1, 18, 512)        \n",
    "        \n",
    "        # calculate losses\n",
    "        r['perceptual_loss'].append(proj.get_vgg_loss(im_orig, latents))\n",
    "        r['mean_abs_corr'].append(np.mean(np.abs(np.corrcoef(latents[0]))))\n",
    "\n",
    "        # calculate predictions for each label\n",
    "        latents_mean = np.mean(latents, axis=1)\n",
    "        preds = (latents_mean @ coefs.transpose() + intercepts)\n",
    "        preds = (preds > 0) * 1\n",
    "        preds[preds == 0] = -1\n",
    "        preds = preds.flatten()\n",
    "        for i, a in enumerate(all_attrs):\n",
    "            r[f'pred_{a}'].append(preds[i])\n",
    "            r[f'lab_{a}'].append(labs.iloc[im_num + 1][attr_map[a]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
