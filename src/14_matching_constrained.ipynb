{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join as oj\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import models\n",
    "import util\n",
    "import os\n",
    "import config\n",
    "from config import ATTR_TO_INDEX\n",
    "import viz\n",
    "import scipy.stats\n",
    "from tqdm import tqdm\n",
    "import figs\n",
    "import matplotlib.image as mpimg\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import seaborn as sns\n",
    "import data\n",
    "import transects\n",
    "import face_recognition\n",
    "import sklearn.metrics\n",
    "from matching import *\n",
    "from matplotlib.image import BboxImage\n",
    "from matplotlib.transforms import Bbox, TransformedBbox\n",
    "\n",
    "\n",
    "df = data.load_all_labs()\n",
    "df = df.set_index('fname_id')\n",
    "\n",
    "DIR_ORIG = '../data/celeba-hq/ims/'\n",
    "DIRS_GEN = '../data_processed/celeba-hq/'\n",
    "reg = 0.1\n",
    "DIR_GEN = oj(DIRS_GEN, f'generated_images_{reg}')\n",
    "\n",
    "# get fnames\n",
    "fname_nps = [f for f in sorted(os.listdir(DIR_GEN)) if 'npy' in f]\n",
    "fname_ids = np.array([f[:-4] for f in fname_nps])\n",
    "\n",
    "# trim df to only have the relevant ids\n",
    "df = df.loc[fname_ids]\n",
    "\n",
    "# load the linear model in latent space\n",
    "coefs, intercepts = transects.get_directions()\n",
    "coefs = np.array(coefs).squeeze()\n",
    "intercepts = np.array(intercepts)\n",
    "\n",
    "\n",
    "# load latents and calculate dists\n",
    "print('loading latents...')\n",
    "latents = np.array([np.load(oj(DIR_GEN, f)) for f in fname_nps])\n",
    "lats = get_lat(latents)\n",
    "preds = lats @ coefs.T + intercepts.T\n",
    "weights = np.zeros(preds.shape[1])\n",
    "# print(ATTR_TO_INDEX)\n",
    "# weights[ATTR_TO_INDEX['skin-color']] = 1e2\n",
    "vecs = join_vecs(preds, lats, weights)\n",
    "\n",
    "print('calculating dists...')\n",
    "dists = get_dists(vecs)\n",
    "print('done!')\n",
    "\n",
    "# load pairwise facial dicts\n",
    "dists_facial_dict = pkl.load(open('processed/13_facial_dists_pairwise.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implement constraints on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find matching for an im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img 38 is a good gender example\n",
    "for im_idx in range(38, 40):\n",
    "    # if all images are calculated, then this is just 5-char string of im_idx + 1\n",
    "    fname_id = fname_ids[im_idx] \n",
    "    \n",
    "    # idxs\n",
    "    dists_im = dists[im_idx]\n",
    "    \n",
    "    # select subset of indices to use for matching\n",
    "    idxs = np.ones(df.shape[0]).astype(bool)\n",
    "    idxs = (df['gender'] > 0).values\n",
    "#     idxs = (df['race'] == 'Black').values\n",
    "#     idxs = (df['Eyeglasses'] > 0).values\n",
    "    dists_im = dists_im[idxs]\n",
    "    fname_ids_for_matching = fname_ids[idxs]    \n",
    "    \n",
    "    closest_match_vals, closest_matches_fnames = calc_matches(dists_im, fname_ids_for_matching)\n",
    "    # print(closest_matches_fnames)\n",
    "    \n",
    "    # load images\n",
    "    N_MATCHES_TO_PLOT = 5\n",
    "    im_orig = mpimg.imread(oj(DIR_ORIG, f'{fname_id}.jpg'))\n",
    "    im_rec = mpimg.imread(oj(DIR_GEN, f'{fname_id}.png'))\n",
    "    im_matches = [mpimg.imread(oj(DIR_GEN, f'{fname_match}.png'))\n",
    "                  for fname_match in closest_matches_fnames[:N_MATCHES_TO_PLOT]]\n",
    "    \n",
    "    # plt images\n",
    "    util.plot_row([im_orig, im_rec] + im_matches, dpi=50)\n",
    "    plt.show()\n",
    "    # print(closest_matches, closest_matches_fnames)\n",
    "# show_matches(dists, DIR_ORIG, DIR_GEN, im_nums=range(5, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate matching with metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**how often do we return the same id?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 100.33it/s]\n"
     ]
    }
   ],
   "source": [
    "d = df[df['count_with_this_id'] > 1]\n",
    "# print(d.shape)\n",
    "\n",
    "acc_top1 = []\n",
    "acc_top5 = []\n",
    "acc_top10 = []\n",
    "for im_idx in tqdm(range(1000)):\n",
    "    id_orig = df.iloc[im_idx].id\n",
    "    \n",
    "    # idxs\n",
    "    dists_im = dists[im_idx]\n",
    "    matched_idxs = np.argsort(dists_im)\n",
    "    matched_ids = df.iloc[matched_idxs].id.values # note - this needs to be df not d to get the proper indices from dists\n",
    "    acc_top1.append(id_orig == matched_ids[0])\n",
    "    acc_top5.append(id_orig in matched_ids[:5])\n",
    "    acc_top10.append(id_orig in matched_ids[:10])\n",
    "print('top1', np.mean(acc_top1), 'top5', np.mean(acc_top5), 'top10', np.mean(acc_top10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
