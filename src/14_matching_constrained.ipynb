{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cached labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.ridge module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Ridge from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.svm.classes module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.svm. Anything that cannot be imported from sklearn.svm is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reload latents...\n",
      "calculating dists...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join as oj\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import models\n",
    "import util\n",
    "import os\n",
    "import config\n",
    "from config import ATTR_TO_INDEX\n",
    "import viz\n",
    "import scipy.stats\n",
    "from tqdm import tqdm\n",
    "import figs\n",
    "import matplotlib.image as mpimg\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import seaborn as sns\n",
    "import data\n",
    "import transects\n",
    "import face_recognition\n",
    "import sklearn.metrics\n",
    "from matching import *\n",
    "\n",
    "df = data.load_all_labs()\n",
    "df = df.set_index('fname_id')\n",
    "\n",
    "DIR_ORIG = '../data/celeba-hq/ims/'\n",
    "DIRS_GEN = '../data_processed/celeba-hq/'\n",
    "reg = 0.1\n",
    "DIR_GEN = oj(DIRS_GEN, f'generated_images_{reg}')\n",
    "\n",
    "# get fnames\n",
    "fname_nps = [f for f in sorted(os.listdir(DIR_GEN)) if 'npy' in f] # these start at 00001\n",
    "fname_ids = np.array([f[:-4] for f in fname_nps])\n",
    "idxs_calculated = np.array([int(x) - 1 for x in fname_ids]) # this starts at 0\n",
    "\n",
    "# trim df to only have the relevant ids\n",
    "df = df.loc[fname_ids]\n",
    "\n",
    "# load the linear model in latent space\n",
    "coefs, intercepts = transects.get_directions()\n",
    "coefs = np.array(coefs).squeeze()\n",
    "intercepts = np.array(intercepts)\n",
    "\n",
    "\n",
    "# load latents and calculate dists\n",
    "print('reload latents...')\n",
    "latents = np.array([np.load(oj(DIR_GEN, f)) for f in fname_nps])\n",
    "lats = get_lat(latents)\n",
    "preds = lats @ coefs.T + intercepts.T\n",
    "weights = np.zeros(preds.shape[1])\n",
    "# print(ATTR_TO_INDEX)\n",
    "# weights[ATTR_TO_INDEX['skin-color']] = 1e2\n",
    "vecs = join_vecs(preds, lats, weights)\n",
    "\n",
    "print('calculating dists...')\n",
    "dists_gan = get_dists(vecs)\n",
    "print('done!')\n",
    "\n",
    "# load pairwise facial dicts\n",
    "dists_facial = np.load(open('processed/13_facial_dists_pairwise.npy', 'rb')) # pkl.load()\n",
    "dists_facial = dists_facial[idxs_calculated, :][:, idxs_calculated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape, df.id.unique().size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find best matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "we want to find matched pairs\n",
    "the pairs should change only one attribute at a time (but we may vary 2 to make a transect)\n",
    "\"main\" image is matched stringently\n",
    "\"reference\" image is matched more loosely\n",
    "'''\n",
    "\n",
    "# specify constraint for reference\n",
    "def apply_reference_constraints(d):\n",
    "    REFERENCE_CONSTRAINTS = {\n",
    "        'Eyeglasses': 0, # default should be no Eyeglasses\n",
    "    }\n",
    "    for k in REFERENCE_CONSTRAINTS.keys():\n",
    "        d = d[k == REFERENCE_CONSTRAINTS[k]]\n",
    "    return d\n",
    "\n",
    "# specify things to vary (these should all be binary columns)\n",
    "attrs_to_vary = ['gender'] # Eyeglasses, gender, Race\n",
    "\n",
    "# specify whether to require id to be different\n",
    "# only false for id-preserving attributes, such as Eyeglasses\n",
    "require_ids_different = True\n",
    "\n",
    "# specify dists for matching\n",
    "dists = dists_facial\n",
    "n = dists.shape[0]\n",
    "assert df.shape[0] == n\n",
    "\n",
    "## remove ims with no reference image satisfying reference constraints\n",
    "idxs_orig = np.ones(n).astype(bool)\n",
    "for i in sorted(df.id.unique()):\n",
    "    idxs = df.id == i\n",
    "    d = df[idxs_orig]\n",
    "    locs = d.index\n",
    "    \n",
    "    # only one photo for this id\n",
    "    if d.shape[0] == 1:\n",
    "        idxs_orig[locs] = False\n",
    "\n",
    "\n",
    "    # prune photos if no valid ref\n",
    "    d_ref = apply_reference_constraints(d)\n",
    "    \n",
    "    # don't pick this id if there is no valid ref\n",
    "    if d_ref.shape[0] < 1:\n",
    "        idxs_orig[locs] = False\n",
    "\n",
    "    # don't select ref photo if it's the only one\n",
    "    elif d_ref.shape[0] == 1:\n",
    "        idxs_orig[d_ref.index] = False \n",
    "        \n",
    "    \n",
    "# find allowed indices for each group\n",
    "subgroups = {}\n",
    "for a in attrs_to_vary:\n",
    "    for val in [0, 1]:\n",
    "        subgroups[f'{a}_{val}'] = (df[a] == val) & idxs_orig\n",
    "\n",
    "# loop to create best matches\n",
    "for i, a in enumerate(attrs_to_vary):\n",
    "    # this should go in order from smaller groups -> bigger groups\n",
    "#     vals = np.argsort([np.sum(subgroups[f'{a}_{val}']) for val in [0, 1]])\n",
    "#     for j, val in enumerate([0, 1]):\n",
    "\n",
    "\n",
    "\n",
    "    ## find best match subject to constraints\n",
    "    idxs0 = subgroups[f'{a}_{0}']\n",
    "    idxs1 = subgroups[f'{a}_{1}']\n",
    "    arg = np.argmin(dists[idxs0][:, idxs1])\n",
    "    arg0 = arg // np.sum(idxs0)\n",
    "    arg1 = arg % np.sum(idxs0)\n",
    "    idx0 = np.nonzero(idxs0)[arg0]\n",
    "    idx1 = np.nonzero(idxs1)[arg1]\n",
    "\n",
    "    ## find best reference images\n",
    "    \n",
    "    \n",
    "\n",
    "    ## if best reference image isn't great, then continue\n",
    "\n",
    "    ## save the pairs\n",
    "\n",
    "    ## remove them from further consideration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find matching for an im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img 38 is a good gender example\n",
    "for im_idx in range(38, 40):\n",
    "    # if all images are calculated, then this is just 5-char string of im_idx + 1\n",
    "    fname_id = fname_ids[im_idx] \n",
    "    \n",
    "    # idxs\n",
    "    dists_im = dists[im_idx]\n",
    "    \n",
    "    # select subset of indices to use for matching\n",
    "    idxs = np.ones(df.shape[0]).astype(bool)\n",
    "    idxs = (df['gender'] > 0).values\n",
    "#     idxs = (df['race'] == 'Black').values\n",
    "#     idxs = (df['Eyeglasses'] > 0).values\n",
    "    dists_im = dists_im[idxs]\n",
    "    fname_ids_for_matching = fname_ids[idxs]    \n",
    "    \n",
    "    closest_match_vals, closest_matches_fnames = calc_matches(dists_im, fname_ids_for_matching)\n",
    "    # print(closest_matches_fnames)\n",
    "    \n",
    "    # load images\n",
    "    N_MATCHES_TO_PLOT = 5\n",
    "    im_orig = mpimg.imread(oj(DIR_ORIG, f'{fname_id}.jpg'))\n",
    "    im_rec = mpimg.imread(oj(DIR_GEN, f'{fname_id}.png'))\n",
    "    im_matches = [mpimg.imread(oj(DIR_GEN, f'{fname_match}.png'))\n",
    "                  for fname_match in closest_matches_fnames[:N_MATCHES_TO_PLOT]]\n",
    "    \n",
    "    # plt images\n",
    "    util.plot_row([im_orig, im_rec] + im_matches, dpi=50)\n",
    "    plt.show()\n",
    "    # print(closest_matches, closest_matches_fnames)\n",
    "# show_matches(dists, DIR_ORIG, DIR_GEN, im_nums=range(5, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
