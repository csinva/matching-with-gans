{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading labels...\n",
      "done loading!\n",
      "loading latents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.ridge module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Ridge from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.svm.classes module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.svm. Anything that cannot be imported from sklearn.svm is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating dists...\n",
      "done!\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "STACK_GLOBAL requires str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1708ba17f40e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# load pairwise facial dicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mdists_facial_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed/13_facial_dists_pairwise.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m: STACK_GLOBAL requires str"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join as oj\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import models\n",
    "import util\n",
    "import os\n",
    "import config\n",
    "from config import ATTR_TO_INDEX\n",
    "import viz\n",
    "import scipy.stats\n",
    "from tqdm import tqdm\n",
    "import figs\n",
    "import matplotlib.image as mpimg\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import seaborn as sns\n",
    "import data\n",
    "import transects\n",
    "import face_recognition\n",
    "import sklearn.metrics\n",
    "from matching import *\n",
    "from matplotlib.image import BboxImage\n",
    "from matplotlib.transforms import Bbox, TransformedBbox\n",
    "\n",
    "\n",
    "df = data.load_all_labs()\n",
    "df = df.set_index('fname_id')\n",
    "\n",
    "DIR_ORIG = '../data/celeba-hq/ims/'\n",
    "DIRS_GEN = '../data_processed/celeba-hq/'\n",
    "reg = 0.1\n",
    "DIR_GEN = oj(DIRS_GEN, f'generated_images_{reg}')\n",
    "\n",
    "# get fnames\n",
    "fname_nps = [f for f in sorted(os.listdir(DIR_GEN)) if 'npy' in f]\n",
    "fname_ids = np.array([f[:-4] for f in fname_nps])\n",
    "\n",
    "# trim df to only have the relevant ids\n",
    "df = df.loc[fname_ids]\n",
    "\n",
    "# load the linear model in latent space\n",
    "coefs, intercepts = transects.get_directions()\n",
    "coefs = np.array(coefs).squeeze()\n",
    "intercepts = np.array(intercepts)\n",
    "\n",
    "\n",
    "# load latents and calculate dists\n",
    "print('loading latents...')\n",
    "latents = np.array([np.load(oj(DIR_GEN, f)) for f in fname_nps])\n",
    "lats = get_lat(latents)\n",
    "preds = lats @ coefs.T + intercepts.T\n",
    "weights = np.zeros(preds.shape[1])\n",
    "# print(ATTR_TO_INDEX)\n",
    "# weights[ATTR_TO_INDEX['skin-color']] = 1e2\n",
    "vecs = join_vecs(preds, lats, weights)\n",
    "\n",
    "print('calculating dists...')\n",
    "dists = get_dists(vecs)\n",
    "print('done!')\n",
    "\n",
    "# load pairwise facial dicts\n",
    "dists_facial_dict = pkl.load(open('processed/13_facial_dists_pairwise.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implement constraints on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape, df.id.unique()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find matching for an im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img 38 is a good gender example\n",
    "for im_idx in range(38, 40):\n",
    "    # if all images are calculated, then this is just 5-char string of im_idx + 1\n",
    "    fname_id = fname_ids[im_idx] \n",
    "    \n",
    "    # idxs\n",
    "    dists_im = dists[im_idx]\n",
    "    \n",
    "    # select subset of indices to use for matching\n",
    "    idxs = np.ones(df.shape[0]).astype(bool)\n",
    "    idxs = (df['gender'] > 0).values\n",
    "#     idxs = (df['race'] == 'Black').values\n",
    "#     idxs = (df['Eyeglasses'] > 0).values\n",
    "    dists_im = dists_im[idxs]\n",
    "    fname_ids_for_matching = fname_ids[idxs]    \n",
    "    \n",
    "    closest_match_vals, closest_matches_fnames = calc_matches(dists_im, fname_ids_for_matching)\n",
    "    # print(closest_matches_fnames)\n",
    "    \n",
    "    # load images\n",
    "    N_MATCHES_TO_PLOT = 5\n",
    "    im_orig = mpimg.imread(oj(DIR_ORIG, f'{fname_id}.jpg'))\n",
    "    im_rec = mpimg.imread(oj(DIR_GEN, f'{fname_id}.png'))\n",
    "    im_matches = [mpimg.imread(oj(DIR_GEN, f'{fname_match}.png'))\n",
    "                  for fname_match in closest_matches_fnames[:N_MATCHES_TO_PLOT]]\n",
    "    \n",
    "    # plt images\n",
    "    util.plot_row([im_orig, im_rec] + im_matches, dpi=50)\n",
    "    plt.show()\n",
    "    # print(closest_matches, closest_matches_fnames)\n",
    "# show_matches(dists, DIR_ORIG, DIR_GEN, im_nums=range(5, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate matching with metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**how often do we return the same id?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 100.33it/s]\n"
     ]
    }
   ],
   "source": [
    "d = df[df['count_with_this_id'] > 1]\n",
    "# print(d.shape)\n",
    "\n",
    "acc_top1 = []\n",
    "acc_top5 = []\n",
    "acc_top10 = []\n",
    "for im_idx in tqdm(range(1000)):\n",
    "    id_orig = df.iloc[im_idx].id\n",
    "    \n",
    "    # idxs\n",
    "    dists_im = dists[im_idx]\n",
    "    matched_idxs = np.argsort(dists_im)\n",
    "    matched_ids = df.iloc[matched_idxs].id.values # note - this needs to be df not d to get the proper indices from dists\n",
    "    acc_top1.append(id_orig == matched_ids[0])\n",
    "    acc_top5.append(id_orig in matched_ids[:5])\n",
    "    acc_top10.append(id_orig in matched_ids[:10])\n",
    "print('top1', np.mean(acc_top1), 'top5', np.mean(acc_top5), 'top10', np.mean(acc_top10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
