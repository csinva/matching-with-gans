{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from os.path import join as oj\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import pickle as pkl\n",
    "sys.path.append('..')\n",
    "\n",
    "import data\n",
    "import style\n",
    "import config\n",
    "from config import *\n",
    "import util\n",
    "import glob\n",
    "import json, jsonlines\n",
    "\n",
    "df = data.load_all_labs()\n",
    "df = df.set_index('fname_id')\n",
    "\n",
    "# get fnames\n",
    "fname_nps = [f for f in sorted(os.listdir(DIR_GEN)) if 'npy' in f] # these start at 00001\n",
    "fname_ids = np.array([f[:-4] for f in fname_nps])\n",
    "idxs_calculated = np.array([int(x) - 1 for x in fname_ids]) # this starts at 0\n",
    "\n",
    "# trim df to only have the relevant ids\n",
    "df = df.loc[fname_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select celebrities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Black | 91 ids\t 468 photos\n",
      "0 White | 1468 ids\t 8536 photos\n",
      "1 Black | 157 ids\t 570 photos\n",
      "1 White | 842 ids\t 3608 photos\n"
     ]
    }
   ],
   "source": [
    "# only consider ids with more than 2 ims\n",
    "d = df[df['count_with_this_id'] > 2]\n",
    "\n",
    "# sort by how many ids each image has\n",
    "d = d.sort_values('count_with_this_id', ascending=False)\n",
    "\n",
    "# get ids for subgroups\n",
    "subgroups = {}\n",
    "for gender in [0, 1]:\n",
    "    for race in ['Black', 'White']:\n",
    "        dd = d[d['gender'] == gender]\n",
    "        dd = dd[dd['race_pred'] == race]\n",
    "        print(gender, race, '|', dd.id.unique().size, 'ids\\t', dd.shape[0], 'photos')        \n",
    "        subgroups[(gender, race)] = dd.id.unique()\n",
    "\n",
    "def pair_plot(im0, im1):\n",
    "    R, C = 1, 2\n",
    "    plt.subplot(R, C, 1)\n",
    "    plt.title('Real photo')\n",
    "    util.imshow(im0)\n",
    "    plt.subplot(R, C, 2)\n",
    "    plt.title('Test photo')\n",
    "    util.imshow(im1)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def slight_random_crop(im):\n",
    "    x = np.random.randint(20, 35)\n",
    "    return im[x: -x, x: -x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "N_IMS = 30\n",
    "EXPERIMENT_DIR = oj(DIR_PROCESSED, 'projections_annotation_double', 'ims')\n",
    "os.makedirs(EXPERIMENT_DIR, exist_ok=True)\n",
    "for gender, race in tqdm(subgroups.keys()):\n",
    "    # print(gender, race)\n",
    "    ids = subgroups[(gender, race)]\n",
    "    for i in tqdm(ids[:N_IMS]):\n",
    "        ims = d[d.id == i].iloc[:2]\n",
    "        im0 = mpimg.imread(oj(DIR_IMS, ims.fname_final.values[0]))\n",
    "        im1 = mpimg.imread(oj(DIR_IMS, ims.fname_final.values[1]))\n",
    "        im1_rec = mpimg.imread(oj(DIR_GEN, ims.fname_final.values[1][:-4] + '.png'))\n",
    "        pair_plot(im0, im1)\n",
    "        plt.savefig(oj(EXPERIMENT_DIR, f'{gender}_{race}_{i}_real.png'), dpi=300)\n",
    "        pair_plot(im0, im1_rec)\n",
    "        plt.savefig(oj(EXPERIMENT_DIR, f'{gender}_{race}_{i}_fake.png'), dpi=300)\n",
    "        pair_plot(im0, slight_random_crop(im0))\n",
    "        plt.savefig(oj(EXPERIMENT_DIR, f'{gender}_{race}_{i}_dup.png'), dpi=300)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(oj(DIR_PROCESSED, 'projections_annotation_double', 'ims')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/face-disentanglement/data_processed/projection_annotations'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANNOTATIONS_DIR = DIR_PROJ_ANNOTATIONS\n",
    "LABELS_FILE = '/annotation-tool/data.json'\n",
    "OUT_MANIFEST_FILE = '/manifests/output/output.manifest'\n",
    "WORKERS_RESPONSE = '/annotations/worker-response'\n",
    "OUTPUT_PDF_DIR = './figures' # location of output pdfs\n",
    "\n",
    "\n",
    "sys.path.append(oj(DIR_REPO, 'disentangling_latent_space'))\n",
    "from annotation_dset import annotationDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments ['intermediate', 'annotation-tool', 'annotations', 'manifests']\n",
      "Found 360 images and 76 annotators.\n",
      "['Same person', 'Not same person', '-------------', 'Well', 'Moderately well', 'Not at all'] (360, 3)\n",
      "saved!\n"
     ]
    }
   ],
   "source": [
    "# Get list of experiments in annotation dir. Alternatively, specify ones you care about.\n",
    "annotations_dict = {}\n",
    "annotations_names_dict = {}\n",
    "experiments = [os.path.split(f)[1] for f in glob.glob(os.path.join(ANNOTATIONS_DIR, '*'))]\n",
    "print('experiments', experiments)\n",
    "experiments = ['.'] #'perona-causal-faces-uncanny-000']\n",
    "\n",
    "# If output directory doesn't exist, make it\n",
    "if not os.path.exists(OUTPUT_PDF_DIR):\n",
    "    os.makedirs(OUTPUT_PDF_DIR)\n",
    "\n",
    "# Do analysis figures for each experiment\n",
    "for EXPERIMENT_LABEL in experiments:\n",
    "    ANNOTATIONS_PATH = f'{ANNOTATIONS_DIR}/{EXPERIMENT_LABEL}{WORKERS_RESPONSE}'\n",
    "    OUT_MANIFEST_PATH = f'{ANNOTATIONS_DIR}/{EXPERIMENT_LABEL}{OUT_MANIFEST_FILE}'\n",
    "    LABELS_PATH = f'{ANNOTATIONS_DIR}/{EXPERIMENT_LABEL}{LABELS_FILE}'\n",
    "    OUT_PDF_FILE_NAME = os.path.join(OUTPUT_PDF_DIR, EXPERIMENT_LABEL + '.pdf')\n",
    "\n",
    "    #Read labels using annotation-tool/data.json and assign integers to labels \n",
    "    with open(LABELS_PATH, 'r') as labels_file:\n",
    "        labels_data = json.load(labels_file)['labels']\n",
    "        LABELS = [l['label'] for l in labels_data]\n",
    "    # labelScores = {l:i for (i, l) in enumerate(LABELS)} # generate numerical scores for the labels - useful in regression\n",
    "    labelScores = {l:l for (i, l) in enumerate(LABELS)} # generate numerical scores for the labels - useful in regression\n",
    "\n",
    "    # Get ordered list of image names from output manifest\n",
    "    image_names = []\n",
    "    with jsonlines.open(OUT_MANIFEST_PATH) as reader:\n",
    "        for obj in reader:\n",
    "            _, name = os.path.split(obj['source-ref']) #remove leading path\n",
    "            image_names.append(name)\n",
    "\n",
    "    # Make map from annotation index to image index\n",
    "    idx_map = []\n",
    "    with jsonlines.open(OUT_MANIFEST_PATH) as reader:\n",
    "        for obj in reader:\n",
    "            _, name = os.path.split(obj['source-ref']) #remove leading path\n",
    "#             print(name)\n",
    "            idx = name.split('.')[0]\n",
    "            idx_map.append(idx)\n",
    "#     print(idx_map)\n",
    "    \n",
    "  \n",
    "    # Make annotation file name list in proper order\n",
    "    '''\n",
    "    annotation_file_names = []\n",
    "    for i in range(len(idx_map)):\n",
    "        idx = idx_map.index(str(i))\n",
    "        annotation_file_names += glob.glob(ANNOTATIONS_PATH + '/*/%d/*.json'% idx)    \n",
    "    print(annotation_file_names)\n",
    "    '''\n",
    "    \n",
    "\n",
    "    # Make annotation file name list in proper order (keep same order)\n",
    "    annotation_file_names = []\n",
    "    for i in range(len(idx_map)):\n",
    "        annotation_file_names += glob.glob(ANNOTATIONS_PATH + '/*/%d/*.json'% i)\n",
    "\n",
    "\n",
    "        \n",
    "    # put together the database of the annotator IDs and their work\n",
    "    annotations = annotationDatabase(annotation_file_names, labelScores, label_type='crowd-image-classifier-multi-select')\n",
    "    annotations.startPDFReport(OUT_PDF_FILE_NAME, EXPERIMENT_LABEL)\n",
    "    fig = annotations.displayAnnotatorsWork()\n",
    "#     annotations.displaySequenceAnnotations(image_names, LABELS, SEQUENCE_LENGTH, IMAGE_PATH)\n",
    "    annotations.endPDFReport()\n",
    "    \n",
    "    print(LABELS, np.array(annotations.imageScores).shape)\n",
    "    annotations_dict[EXPERIMENT_LABEL] = np.array(annotations.imageScores)\n",
    "    annotations_names_dict[EXPERIMENT_LABEL] = LABELS\n",
    "\n",
    "mat_list = annotations_dict['.']\n",
    "print('saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num annotators plot\n",
    "n_annotations = sorted(annotations.annotations, reverse=True)\n",
    "plt.figure(dpi=300)\n",
    "plt.grid()\n",
    "plt.plot(range(1, 1 + annotations.N_ANNOTATORS), n_annotations)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of annotators')\n",
    "plt.ylabel('Number of annotations')\n",
    "plt.title('Work of individual annotators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list(['Same person']), list(['Same person', 'Well']),\n",
       "        list(['Same person', 'Well'])],\n",
       "       [list(['Same person']), list(['Same person']),\n",
       "        list(['Moderately well'])],\n",
       "       [list(['Not same person']), list(['Not same person']),\n",
       "        list(['Not same person'])],\n",
       "       ...,\n",
       "       [list(['Same person']), list(['Same person', 'Well']),\n",
       "        list(['Same person'])],\n",
       "       [list(['Not same person']), list(['Same person']),\n",
       "        list(['Not same person', 'Moderately well'])],\n",
       "       [list(['-------------', 'Not same person']),\n",
       "        list(['Not same person', 'Well']), list(['Not same person'])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(annotations_dict['.'][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(annotations_dict['.'][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-0643f85d64ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'label_names' is not defined"
     ]
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
